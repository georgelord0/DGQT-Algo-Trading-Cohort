{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0b2ecba",
   "metadata": {},
   "source": [
    "## Step 0: Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c2f39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb635416",
   "metadata": {},
   "source": [
    "## Step 1: Getting stock price data as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951e1122",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_ticker = \"MSFT\"  # Microsoft\n",
    "data = yf.download(stock_ticker, start=\"2023-01-01\", end=\"2024-01-01\")  # Get last year's daily price data for MSFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e25d010",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)  # yfinance (Yahoo Finance) automatically returns a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81b4cc7",
   "metadata": {},
   "source": [
    "## Step 2: Getting returns of stock data with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9083d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)  # Inspect the first 5 rows of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530816dc",
   "metadata": {},
   "source": [
    "The **return** of a stock is defined as the assets's change in value over some period of time. In quantitative investing and algorithmic trading, we often use the **percent return** of an asset over some period (minute by minute, day over day, etc.) in our modeling rather than the exact price over time.\n",
    "\n",
    "This is because while the scale of an asset's price can change greatly over time (e.g. BTC started at 13 in 2012, and is now near 100,000), returns represented as a percentage are *scale free* and *stationary*, making statistical figures like mean, variance, correlations, etc. more useful. The use of percent returns will become more apparent in the following lectures!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58498aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Pct Return\"] = data['Close'].pct_change()  # Calculate daily percent return\n",
    "data[\"Pct Return\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28192d02",
   "metadata": {},
   "source": [
    "## Step 3: Analyzing Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab0b86e",
   "metadata": {},
   "source": [
    "Now that we have daily pct returns data, we can looks at some quantitative metrics of the performance of our asset over the time frame of our data. For example, mean, standard deviation, highs, lows, and percentiles all give us a better picture of the performance of our asset (**Week 2 foreshadowing**: particularly mean and stardard deviation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf10b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Pct Return\"].describe()  # .describe() gives us several useful summary stats for a numerical column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddea9626",
   "metadata": {},
   "source": [
    "Here we see that the average (mean) daily return (percent change) of MSFT in 2023 is 0.1936%, and see other useful metrics.\n",
    "\n",
    "We can also use specific methods for various summary statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351c59bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['Pct Return'].mean()  # Mean\n",
    "#data['Pct Return'].median()  # Median\n",
    "#data['Pct Return'].mode()  # Mode\n",
    "#data['Pct Return'].std()  # Standard Deviation\n",
    "#data['Pct Return'].var()  # Variance\n",
    "#data['Pct Return'].sum()  # Sum\n",
    "#data['Pct Return'].count()  # Count (number of rows)\n",
    "#data['Pct Return'].min()  # Minimum value\n",
    "#data['Pct Return'].max()  # Maximum Value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3190aebd",
   "metadata": {},
   "source": [
    "## Step 4: Basic Feature Engineering for Algorithmic Trading Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0369833",
   "metadata": {},
   "source": [
    "In order to gain some fluency with Pandas, we will create some features.\n",
    "\n",
    "\"Feature engineering is the process of selecting, manipulating and transforming raw data into features that can be used in supervised learning. It's also necessary to design and train new machine learning features so it can tackle new tasks. A “feature” is any measurable input that can be used in a predictive model.\"\n",
    "\n",
    "Let's start with a *Simple Moving Average*. This is defined as the average of the current element at a time and the last n-1 elements before it. SMAs are used widely in various trading strategies (such as moving average crossover) and technical indicators (such as Bollinger Bands). More on that next week!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f580b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"SMA\"] = data[\"Close\"].rolling(5).mean()  # SMA of last 5 days of MSFT close price\n",
    "data[\"SMA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1e573b",
   "metadata": {},
   "source": [
    "Another useful feature used widely in algorithmic trading is *z-scores*. \n",
    "\n",
    "\"In algorithmic trading, a \"z-score\" is a statistical measure that indicates how far away a particular data point (like a stock price) is from the historical average price, expressed in terms of standard deviations, essentially showing whether the current price is considered \"normal\" or an outlier compared to past price movements; traders use z-scores to identify potential trading opportunities based on significant deviations from the mean, allowing them to potentially capitalize on price reversals or strong trends.\"\n",
    "\n",
    "**Note**: In an algorithm that is actually trading live, it would be unrealistic to use the mean and std of the entire time series we trade on, as we cannot see the future, nor do we want calculations to be too intense with all emassed previous data. Hence, z-scores tend to be calculated on a rolling basis in trading algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d8f412",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_mean = data[\"Close\"].rolling(30).mean()  # This is the 30-day SMA of close\n",
    "rolling_std = data[\"Close\"].rolling(30).std()  # 30 day rolling STD of close\n",
    "data[\"Z-score\"] = ((data[\"Close\"] - rolling_mean) / rolling_std)  # 30-day rolling zscore of close\n",
    "data[\"Z-score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e8fbed",
   "metadata": {},
   "source": [
    "## Step 5: Plotting Price and Returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e762fd25",
   "metadata": {},
   "source": [
    "It's hard to interpret all this useful data without being able to visualize it. To do so, we can make some basic plots with matplotlib. Matplotlib has many different functionalities for building various plots, which can be found in the docs here: https://matplotlib.org/3.5.3/api/_as_gen/matplotlib.pyplot.html\n",
    "\n",
    "Pro tip: ChatGPT can be a good time-saver for getting code for specific visualization (just take the code with a grain of salt)!\n",
    "\n",
    "For now, let's plot the daily price and returns of MSFT in 2023:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89425e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Daily Close Price\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data.index, data['Close'], label=\"MSFT Close Price\")\n",
    "plt.title(\"MSFT Daily Close Price 2023\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Close Price (USD)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be06f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Daily Returns:\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data.index, data['Pct Return'], label=\"MSFT Pct Change\")\n",
    "plt.title(\"MSFT Daily Pct Return 2023\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"MSFT Pct Change\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e061a24",
   "metadata": {},
   "source": [
    "These plots also highlight the scaling and stationarity advantages of using returns rather than just price."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1817462f",
   "metadata": {},
   "source": [
    "**For fun**: Try plotting the SMA and closing price together!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d28938",
   "metadata": {},
   "source": [
    "## Step 6: Using Lagging Regression to Predict Future Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b573331f",
   "metadata": {},
   "source": [
    "Regression is both one of the simplest and commonly used statistical model in quantitative finance. By using the previous (lagging) values of variables as our feature vectors (inputs) and the current percent return as our label vector (target), we can learn a liner regression model that takes the last values of the feature vector and predicts the next percent return. Such a model, if accurate, is powerful because it can inform our algorithm's decision to buy/hold or sell when the next return is estimated to be positive or negative respectively (simplified).\n",
    "\n",
    "The following are just some examples of lagging features we could use in such a model (possibly in combination):\n",
    "1. Lagging \"order book\" data such as lagging close prices, percentage change, high/low/volume\n",
    "2. Lagging rolling window features, such as previous SMA values or z-scores\n",
    "3. More complex features such as Technical Indicators (more on that in following weeks)\n",
    "4. Sector/market prices, such as the lagging value of the S&P 500 (SPY)\n",
    "5. Lagging stock data such as dividend-price ratio, earnings-price ratio, etc.\n",
    "And more.\n",
    "\n",
    "For the sake of simplicity, let's use the last 3 day's returns for MSFT to try and predict it's future returns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20784402",
   "metadata": {},
   "source": [
    "### Step 6a: Preparing Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f6ea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Lag1'] = data['Pct Return'].shift(1)  # 1-day lag\n",
    "data['Lag2'] = data['Pct Return'].shift(2)  # 2-day lag\n",
    "data['Lag3'] = data['Pct Return'].shift(3)  # 3-day lag\n",
    "\n",
    "# Drop SMA and Z-score columns since they are missing first 30 values\n",
    "data.drop([\"SMA\", \"Z-score\"], axis=1, inplace=True)  \n",
    "\n",
    "data.dropna(inplace=True)  # Since the first three days won't have values for all lags, drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3774ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['Lag1', 'Lag2', 'Lag3']]  # Feature Vector\n",
    "y = data['Pct Return']  # Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c75d26",
   "metadata": {},
   "source": [
    "Since we want to be able to analyze the performance of our model on unseen data, let's keep the first 80% of our data as training data and evaluate it on the unseen testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9990f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2  # 20% of data for testing\n",
    "split_index = int(len(X) * (1 - test_size))  # Calculate the split index\n",
    "\n",
    "X = sm.add_constant(X)  # Adding constant for the intercept term\n",
    "\n",
    "X_train = X.iloc[:split_index]\n",
    "X_test = X.iloc[split_index:]\n",
    "y_train = y.iloc[:split_index]\n",
    "y_test = y.iloc[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8028613",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)  # 196 days of training data\n",
    "print(X_test.shape)  # 50 days of test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e294d0",
   "metadata": {},
   "source": [
    "**Question to consider**: Would it be smart to randomly select 80% of the days as training data and the rest as test data, or would we want to keep the training data and test data as continuous time intervals like we did above? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734637e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"Pct Return\", \"Lag1\", \"Lag2\", \"Lag3\"]].head(4)  # Confirming our data looks good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d8f1bb",
   "metadata": {},
   "source": [
    "### Step 6b: Learning our Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7db4eea",
   "metadata": {},
   "source": [
    "For this, we will use Ordinary Least Squares (OLS) from the Statsmodels package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d5b2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols = sm.OLS(y_train, X_train).fit()  # Fit our OLS model to our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbb4779",
   "metadata": {},
   "source": [
    "Now we can see the constant (where the regression \"line\" crosses the y-axis) and the coefficients for each parameter that the OLS regression fit to.\n",
    "\n",
    "Given new feature values (such as lag1, lag2, lag3), the value predicted by our model will be equal to the sum of the features multiplied by their coefficients plus the constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddebb48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e995789a",
   "metadata": {},
   "source": [
    "We can also see the R^2 value of our model, which measures the % of the target variable's variability the model can explain. If R^2 = 1, the model is perfectly fit and explains all variability in the target variable. If R^2 = 0, the model explains none of the variability of the target variable, and may as well just always predict the mean value of the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bab4c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols.rsquared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f538b02f",
   "metadata": {},
   "source": [
    "**Question to consider**: How well do you think the model explains the future returns' variability? Are you suprised by this value? Why or why not? (Hint: Would you expect financial data to be \"noisy\"?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d3432d",
   "metadata": {},
   "source": [
    "### Step 6c: Testing our Model on Unseen Data + Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e8c2a0",
   "metadata": {},
   "source": [
    "Now let's try testing our model on the unseen testing data, and comparing it's predictions to the true values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc2cf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ols.predict(X_test)  # Predict the testing pct_change using the test values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac949eea",
   "metadata": {},
   "source": [
    "We can plot the predicted and real values and compare visually:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44438bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dates = data.reset_index()[\"Date\"].iloc[split_index:]  # Days we are testing on\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(test_dates, y_test, label=\"Real Pct Change\")\n",
    "plt.plot(test_dates, y_pred, label=\"Predicted Pct Change\")\n",
    "plt.title(\"Real Vs. Predicted MSFT Daily Pct Return\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Pct Change\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6cf4bd",
   "metadata": {},
   "source": [
    "To quantitatively evaluate our model, we can calculate the **mean squared error**, which uses the following formula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62afdf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = ((y_test - y_pred) ** 2).mean()\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36cab81",
   "metadata": {},
   "source": [
    "**Question to consider**: Do you think this MSE is high or low, good or bad? Consider the explicit formula, the scale of pct_change, and other factors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735d52d3",
   "metadata": {},
   "source": [
    "## Step 7: Try Stuff Yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2f361c",
   "metadata": {},
   "source": [
    "**For less experienced**: Now that you know how to get stock price data, work with data in Pandas, make plots, and run regression, try making your own regression model! See if you can find good lagging features to predict whichever asset's returns you pick. Feel free to refer to documentation and ChatGPT!\n",
    "\n",
    "**For more experienced**: Do the above, and then backtest your regression model by turning your rolling regression predictions into buy/sell/hold values (can use a for loop or pandas.DataFrame.cumprod)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
